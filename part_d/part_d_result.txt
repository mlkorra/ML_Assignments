-----------------------------------------
Learning Rate : 0.01
-----------------------------------------

Using Gradient Descent with Mean Square Error

After 0 iterations : theta = [ 0.4978258   0.26891887  0.42188353  0.41763844  0.01797944],Error = [ 1998.51653738  3928.24965015  3083.5794992  ...,  1198.35004504
   158.24411907  3368.8109948 ]

After 100 iterations : theta = [ 0.16944184  0.26835146  0.28113079  0.41726    -0.07222418],Error = [  172.2328245    497.55711757   408.4372461  ...,    38.27273255
  1356.65209826    35.36555671]

After 200 iterations : theta = [ 0.07641312  0.26804752  0.24073403  0.41705007 -0.094331  ],Error = [   17.7843442    119.50685295   104.65448843 ...,   310.73640451
  2558.53648449    73.30854364]

After 300 iterations : theta = [ 0.04963063  0.26781727  0.2285744   0.41688706 -0.09730706],Error = [  2.86409717e+00   5.95652158e+01   5.44978974e+01 ...,   4.32897418e+02
   2.94817209e+03   1.56152390e+02]

After 400 iterations : theta = [ 0.04150299  0.26760731  0.2243563   0.41673678 -0.09493213],Error = [  9.29817317e-01   4.62420296e+01   4.27993355e+01 ...,   4.69148593e+02
   3.04599877e+03   1.81081734e+02]

After 500 iterations : theta = [ 0.03863665  0.26740261  0.22236838  0.41658959 -0.09108372],Error = [  5.51291595e-01   4.26233899e+01   3.92819360e+01 ...,   4.77847876e+02
   3.05722687e+03   1.84495198e+02]

After 600 iterations : theta = [ 0.03726214  0.26719896  0.22100363  0.4164428  -0.08685265],Error = [  4.40716781e-01   4.14606199e+01   3.78551027e+01 ...,   4.78565268e+02
   3.04407454e+03   1.81623584e+02]

After 700 iterations : theta = [ 0.03631841  0.26699517  0.21981005  0.41629566 -0.08254553],Error = [  3.92097636e-01   4.09659189e+01   3.70059843e+01 ...,   4.77046010e+02
   3.02434946e+03   1.77093850e+02]

After 800 iterations : theta = [ 0.03550662  0.26679092  0.21866073  0.41614797 -0.07824822],Error = [  3.60771999e-01   4.06571401e+01   3.63270001e+01 ...,   4.74922284e+02
   3.00306711e+03   1.72217547e+02]

After 900 iterations : theta = [ 0.03474246  0.26658613  0.21752021  0.41599966 -0.07398453],Error = [  3.35410793e-01   4.04005722e+01   3.57053290e+01 ...,   4.72653358e+02
   2.98162975e+03   1.67357217e+02]

Theta : [ 0.0340093   0.26638283  0.21639018  0.41585223 -0.0698028 ]
RMSE (with MSE): 33216474.56969552
Using Gradient Descent with Mean Absolute Error

After 0 iterations : theta = [ 0.49367676  0.26891698  0.42021911  0.41763769  0.01680006],Error = [  2.75599300e-05   3.86730396e-05   3.42662086e-05 ...,   2.12150703e-05
   7.44031564e-06   3.56998613e-05]

After 100 iterations : theta = [ 0.02123488  0.2680529   0.21529394  0.41723283 -0.09070929],Error = [  5.41894396e-07   2.82694482e-06   2.77803090e-06 ...,   1.47991804e-05
   3.56836606e-05   9.76834828e-06]

After 200 iterations : theta = [ 0.01917473  0.26724318  0.19530984  0.41694365 -0.05428777],Error = [  3.97733609e-07   2.63977954e-06   2.59195772e-06 ...,   1.45600168e-05
   3.48233474e-05   9.00036893e-06]

After 300 iterations : theta = [ 0.01746739  0.26643346  0.17655438  0.41665446 -0.02024416],Error = [  2.50359066e-07   2.47494519e-06   2.42940150e-06 ...,   1.43260424e-05
   3.40133020e-05   8.27845438e-06]

After 400 iterations : theta = [ 0.01560388  0.26562375  0.15923944  0.41636528  0.0112716 ],Error = [  1.30291640e-07   2.30756840e-06   2.26334258e-06 ...,   1.41244210e-05
   3.32809390e-05   7.62845877e-06]

After 500 iterations : theta = [ 0.01404575  0.26481403  0.14321209  0.41607609  0.04013185],Error = [  1.17604098e-08   2.15721177e-06   2.11702462e-06 ...,   1.39361632e-05
   3.26139098e-05   7.03991784e-06]

After 600 iterations : theta = [ 0.01290637  0.26400431  0.12838249  0.41578691  0.0661386 ],Error = [  1.10359670e-07   2.02424196e-06   1.99408808e-06 ...,   1.37624000e-05
   3.20208028e-05   6.52292216e-06]

After 700 iterations : theta = [ 0.01191273  0.2631946   0.11510606  0.41549772  0.08949694],Error = [  2.21762483e-07   1.90795291e-06   1.88610012e-06 ...,   1.36033699e-05
   3.14890731e-05   6.06084184e-06]

After 800 iterations : theta = [ 0.01116663  0.26238488  0.10325051  0.41520854  0.11018244],Error = [  3.28158730e-07   1.80946261e-06   1.79658551e-06 ...,   1.34576391e-05
   3.10205440e-05   5.65685373e-06]

After 900 iterations : theta = [ 0.01046912  0.26157516  0.0927622   0.41491935  0.12866157],Error = [  4.21413728e-07   1.72307883e-06   1.71652300e-06 ...,   1.33262753e-05
   3.06038274e-05   5.29858811e-06]

Theta : [ 0.01000411  0.26077354  0.08343518  0.41463306  0.14510433]
RMSE (with ABE): 23957326.62244676

Using Gradient Descent with Mean Cubic Error

After 0 iterations : theta = [ 0.49323198  0.26890447  0.41979012  0.41762771  0.01668287],Error = [  932.668969    2576.11713729  1792.53499652 ...,   424.18396224
    18.01014627  2023.05944343]

After 50 iterations : theta = [ 0.25125755  0.26821708  0.3127661   0.417126   -0.05065341],Error = [  99.34145146  357.67080097  259.82040523 ...,    0.58213143 -165.89679868
   67.83376859]

Theta : [ 0.25125755  0.26821708  0.3127661   0.417126   -0.05065341]
RMSE (with MCE): 138589510.1570957

-----------------------------------------
Learning Rate : 0.02
-----------------------------------------

Using Gradient Descent with Mean Square Error

After 0 iterations : theta = [ 0.49200145  0.26891035  0.41939263  0.41763284  0.01634205],Error = [ 1948.71049783  3838.92387507  3014.36646938 ...,  1148.68057616
   136.89926719  3262.09629275]

Theta : [ 0.16676974  0.26834647  0.27998415  0.41725666 -0.07294908]
RMSE (with MSE): 90290667.65831402
Using Gradient Descent with Mean Absolute Error

After 0 iterations : theta = [ 0.48370336  0.26890657  0.41606381  0.41763133  0.01398329],Error = [  2.69627356e-05   3.79130585e-05   3.36003484e-05 ...,   2.04456691e-05
   6.50874561e-06   3.47188176e-05]

Theta : [ 0.02125802  0.26804364  0.2150559   0.41722878 -0.09047563]
RMSE (with ABE): 32794008.566774584

Using Gradient Descent with Mean Cubic Error

After 0 iterations : theta = [ 0.4828138   0.26888156  0.41520583  0.41761137  0.01374891],Error = [  870.7055381   2419.0215385   1684.87714955 ...,   377.31128884
    11.72289271  1851.13501047]

After 50 iterations : theta = [ 0.17137366  0.26782519  0.27683779  0.41682842 -0.07274878],Error = [  25.28745516  118.37075116   89.56415117 ...,   -2.59831228 -548.35733844
    1.87819807]

Theta : [ 0.17137366  0.26782519  0.27683779  0.41682842 -0.07274878]
RMSE (with MCE): 91885763.0101843

-----------------------------------------
Learning Rate : 0.03
-----------------------------------------

Using Gradient Descent with Mean Square Error

After 0 iterations : theta = [ 0.4861771   0.26890182  0.41690174  0.41762723  0.01470465],Error = [ 1899.53293501  3750.62541808  2945.939048   ...,  1100.0623643
   117.10010467  3157.09911813]

Theta : [ 0.10542089  0.26817594  0.25345406  0.41713969 -0.0882429 ]
RMSE (with MSE): 57450294.11738943
Using Gradient Descent with Mean Absolute Error

After 0 iterations : theta = [ 0.47372997  0.26889616  0.4119085   0.41762496  0.01116652],Error = [  2.63655411e-05   3.71530774e-05   3.29344883e-05 ...,   1.96762679e-05
   5.57717559e-06   3.37377738e-05]

Theta : [ 0.02017994  0.26762953  0.20471987  0.41708361 -0.07169998]
RMSE (with ABE): 31848042.245791305

Using Gradient Descent with Mean Cubic Error

After 0 iterations : theta = [ 0.47239563  0.26885864  0.41062153  0.41759503  0.01081495],Error = [  811.54917027  2268.44601243  1581.61852111 ...,   334.02539247
     7.10117105  1689.23774857]

After 50 iterations : theta = [ 0.13072366  0.26752568  0.25818438  0.41659562 -0.08440223],Error = [  8.88258335e+00   5.44262310e+01   4.28968125e+01 ...,  -1.57523787e+01
  -8.76576463e+02  -1.27167861e-02]

Theta : [ 0.13072366  0.26752568  0.25818438  0.41659562 -0.08440223]
RMSE (with MCE): 69138792.13549618

-----------------------------------------
Learning Rate : 0.04
-----------------------------------------

Using Gradient Descent with Mean Square Error

After 0 iterations : theta = [ 0.48035275  0.2688933   0.41441085  0.41762162  0.01306726],Error = [ 1850.98384892  3663.35427919  2878.29723505 ...,  1052.49540946
    98.8466315   3053.81947093]

Theta : [ 0.07332207  0.26803807  0.23939433  0.41704357 -0.09508035]
RMSE (with MSE): 43168321.445361175
Using Gradient Descent with Mean Absolute Error

After 0 iterations : theta = [ 0.46375657  0.26888575  0.4077532   0.4176186   0.00834975],Error = [  2.57683467e-05   3.63930963e-05   3.22686282e-05 ...,   1.89068667e-05
   4.64560556e-06   3.27567301e-05]

Theta : [ 0.01924529  0.26721542  0.1946576   0.41693381 -0.0535817 ]
RMSE (with ABE): 30954650.50968638

Using Gradient Descent with Mean Cubic Error

After 0 iterations : theta = [ 0.46197745  0.26883572  0.40603723  0.41757869  0.00788099],Error = [  755.13479756  2124.25236699  1482.66734059 ...,   294.18350508
     3.8886885   1537.06637588]

After 50 iterations : theta = [ 0.10498467  0.26727012  0.24612318  0.41639392 -0.09231407],Error = [    3.52876401    29.05626515    23.92052561 ...,   -33.72871667
 -1145.60848231    -1.64711437]

Theta : [ 0.10498467  0.26727012  0.24612318  0.41639392 -0.09231407]
RMSE (with MCE): 55626717.93628934

-----------------------------------------
Learning Rate : 0.05
-----------------------------------------

Using Gradient Descent with Mean Square Error

After 0 iterations : theta = [ 0.4745284   0.26888478  0.41191996  0.41761601  0.01142986],Error = [ 1803.06323955  3577.1104584   2811.44103054 ...,  1005.97971164
    82.13884769  2952.25735115]

Theta : [ 0.05657247  0.26791727  0.23187677  0.4169583  -0.09748641]
RMSE (with MSE): 37564506.278080866
Using Gradient Descent with Mean Absolute Error

After 0 iterations : theta = [ 0.45378318  0.26887534  0.40359789  0.41761224  0.00553297],Error = [  2.51711523e-05   3.56331153e-05   3.16027680e-05 ...,   1.81374655e-05
   3.71403554e-06   3.17756864e-05]

Theta : [ 0.01834072  0.26680478  0.18487237  0.41678517 -0.03603714]
RMSE (with ABE): 30116850.683021918

Using Gradient Descent with Mean Cubic Error

After 0 iterations : theta = [ 0.45155928  0.2688128   0.40145294  0.41756236  0.00494702],Error = [  7.01397352e+02   1.98630241e+03   1.38793184e+03 ...,   2.57642859e+02
   1.82915223e+00   1.39431961e+03]

After 50 iterations : theta = [ 0.08631911  0.26704093  0.23720484  0.41621106 -0.09859407],Error = [    1.41717684    16.58867377    14.3456911  ...,   -53.27880313
 -1377.11209742    -6.69191387]

Theta : [ 0.08631911  0.26704093  0.23720484  0.41621106 -0.09859407]
RMSE (with MCE): 46710474.253014795

-----------------------------------------
Learning Rate : 0.06
-----------------------------------------

Using Gradient Descent with Mean Square Error

After 0 iterations : theta = [ 0.46870404  0.26887626  0.40942906  0.41761041  0.00979247],Error = [ 1755.77110691  3491.89395571  2745.37043446 ...,   960.51527085
    66.97675324  2852.41275879]

Theta : [ 0.04780959  0.26780525  0.2277616   0.4168786  -0.09759287]
RMSE (with MSE): 35413483.37657997
Using Gradient Descent with Mean Absolute Error

After 0 iterations : theta = [ 0.44380978  0.26886493  0.39944259  0.41760588  0.0027162 ],Error = [  2.45739579e-05   3.48731342e-05   3.09369079e-05 ...,   1.73680643e-05
   2.78246551e-06   3.07946426e-05]

Theta : [ 0.01750787  0.26638719  0.17555231  0.41663422 -0.01905087]
RMSE (with ABE): 29345298.81836694

Using Gradient Descent with Mean Cubic Error

After 0 iterations : theta = [ 0.44114111  0.26878989  0.39686864  0.41754602  0.00201306],Error = [  6.50271766e+02   1.85445795e+03   1.29732024e+03 ...,   2.24260685e+02
   6.66269456e-01   1.26069617e+03]

After 50 iterations : theta = [ 0.07137282  0.26682999  0.22995052  0.41604133 -0.10413121],Error = [  5.16404761e-01   9.61715491e+00   8.82254669e+00 ...,  -7.38006846e+01
  -1.58853728e+03  -1.49148735e+01]

Theta : [ 0.07137282  0.26682999  0.22995052  0.41604133 -0.10413121]
RMSE (with MCE): 40531971.85035781

-----------------------------------------
Learning Rate : 0.07
-----------------------------------------

Using Gradient Descent with Mean Square Error

After 0 iterations : theta = [ 0.46287969  0.26886774  0.40693817  0.4176048   0.00815507],Error = [ 1709.10745099  3407.70477112  2680.08544682 ...,   916.10208708
    53.36034814  2754.28569386]

Theta : [ 0.04316693  0.2676977   0.22539995  0.41680169 -0.09651921]
RMSE (with MSE): 34530079.185235865
Using Gradient Descent with Mean Absolute Error

After 0 iterations : theta = [  4.33836385e-01   2.68854515e-01   3.95287279e-01   4.17599516e-01
  -1.00570740e-04],Error = [  2.39767634e-05   3.41131531e-05   3.02710477e-05 ...,   1.65986631e-05
   1.85089548e-06   2.98135989e-05]

Theta : [ 0.01670278  0.26597192  0.16660866  0.41648211 -0.0027023 ]
RMSE (with ABE): 28636274.047975436

Using Gradient Descent with Mean Cubic Error

After 0 iterations : theta = [ 0.43072293  0.26876697  0.39228434  0.41752968 -0.0009209 ],Error = [  6.01692971e+02   1.72858079e+03   1.21074078e+03 ...,   1.93894216e+02
   1.43747364e-01   1.13589477e+03]

After 50 iterations : theta = [ 0.05839577  0.26663301  0.22358771  0.41588171 -0.10938957],Error = [  1.42613701e-01   5.40794954e+00   5.35188407e+00 ...,  -9.57048293e+01
  -1.79325960e+03  -2.62961657e+01]

Theta : [ 0.05839577  0.26663301  0.22358771  0.41588171 -0.10938957]
RMSE (with MCE): 36288625.409436084

-----------------------------------------
Learning Rate : 0.08
-----------------------------------------

Using Gradient Descent with Mean Square Error

After 0 iterations : theta = [ 0.45705534  0.26885921  0.40444728  0.41759919  0.00651768],Error = [ 1663.07227179  3324.54290463  2615.58606762 ...,   872.74016034
    41.2896324   2657.87615635]

Theta : [ 0.04063162  0.26759234  0.22393348  0.41672611 -0.0948482 ]
RMSE (with MSE): 34123502.359491885
Using Gradient Descent with Mean Absolute Error

After 0 iterations : theta = [ 0.42386299  0.2688441   0.39113197  0.41759315 -0.00291734],Error = [  2.33795690e-05   3.33531720e-05   2.96051876e-05 ...,   1.58292619e-05
   9.19325459e-07   2.88325552e-05]

Theta : [ 0.01565478  0.26555897  0.1579933   0.41634388  0.01284687]
RMSE (with ABE): 27981761.666635934

Using Gradient Descent with Mean Cubic Error

After 0 iterations : theta = [ 0.42030476  0.26874405  0.38770005  0.41751334 -0.00385487],Error = [  5.55595900e+02   1.60853275e+03   1.12810169e+03 ...,   1.66400684e+02
   5.29315201e-03   1.01961414e+03]

After 50 iterations : theta = [ 0.04628987  0.26644755  0.21763171  0.41573051 -0.1146687 ],Error = [  1.76694398e-02   2.78233907e+00   3.06288908e+00 ...,  -1.19961061e+02
  -2.00307228e+03  -4.14093618e+01]

Theta : [ 0.04628987  0.26644755  0.21763171  0.41573051 -0.1146687 ]
RMSE (with MCE): 33694159.950996

-----------------------------------------
Learning Rate : 0.09
-----------------------------------------

Using Gradient Descent with Mean Square Error

After 0 iterations : theta = [ 0.45123099  0.26885069  0.40195639  0.41759358  0.00488028],Error = [ 1617.66556933  3242.40835624  2551.87229685 ...,   830.42949061
    30.76460601  2563.18414627]

Theta : [ 0.03916515  0.26748802  0.22291935  0.41665113 -0.09288045]
RMSE (with MSE): 33910545.633028224
Using Gradient Descent with Mean Absolute Error

After 0 iterations : theta = [ 0.4138896   0.26883369  0.38697667  0.41758679 -0.00573412],Error = [  2.27823746e-05   3.25931910e-05   2.89393275e-05 ...,   1.50598607e-05
   1.22445663e-08   2.78515115e-05]

Theta : [ 0.01493297  0.26514833  0.14980093  0.41618136  0.02781561]
RMSE (with ABE): 27390189.28734782

Using Gradient Descent with Mean Cubic Error

After 0 iterations : theta = [ 0.40988658  0.26872114  0.38311575  0.417497   -0.00678883],Error = [  5.11915484e+02   1.49417563e+03   1.04931119e+03 ...,   1.41637321e+02
  -5.38598383e-03   9.11552986e+02]

After 50 iterations : theta = [ 0.0342036   0.2662722   0.2117074   0.41558674 -0.12021501],Error = [ -6.06389660e-09   1.18073564e+00   1.54173888e+00 ...,  -1.48147656e+02
  -2.23070528e+03  -6.16148530e+01]

Theta : [ 0.0342036   0.2662722   0.2117074   0.41558674 -0.12021501]
RMSE (with MCE): 32783507.206762332

-----------------------------------------
Learning Rate : 0.1
-----------------------------------------

Using Gradient Descent with Mean Square Error

After 0 iterations : theta = [ 0.44540664  0.26884217  0.39946549  0.41758798  0.00324289],Error = [ 1572.88734358  3161.30112595  2488.94413451 ...,   789.17007792
    21.78526898  2470.20966361]

Theta : [ 0.03823661  0.26738414  0.22213123  0.41657636 -0.09076961]
RMSE (with MSE): 33782536.772261545
Using Gradient Descent with Mean Absolute Error

After 0 iterations : theta = [ 0.4039162   0.26882328  0.38282136  0.41758043 -0.00855089],Error = [  2.21851802e-05   3.18332099e-05   2.82734673e-05 ...,   1.42904595e-05
   9.43814592e-07   2.68704677e-05]

Theta : [ 0.02773344  0.26474     0.14669313  0.41604197  0.04483286]
RMSE (with ABE): 28765715.267202087

Using Gradient Descent with Mean Cubic Error

After 0 iterations : theta = [ 0.39946841  0.26869822  0.37853145  0.41748066 -0.00972279],Error = [  4.70586655e+02   1.38537123e+03   9.74277510e+02 ...,   1.19461358e+02
  -1.44582848e-01   8.11410030e+02]

After 50 iterations : theta = [ 0.02129311  0.26610617  0.20544433  0.41544988 -0.12629019],Error = [ -2.25164840e-02   3.19243723e-01   5.88380682e-01 ...,  -1.82862358e+02
  -2.49299304e+03  -8.95601321e+01]

Theta : [ 0.02129311  0.26610617  0.20544433  0.41544988 -0.12629019]
RMSE (with MCE): 33835016.12996444
